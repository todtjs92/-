# VQ-VAE를 이용한 음성합성 영어쉐도잉

## 웹화면 구현
![웹_화면](https://user-images.githubusercontent.com/59354220/94262946-44dcdf80-ff6f-11ea-8900-a1784f017ae1.png)
### 시연동영상
https://www.youtube.com/watch?v=7G8h-QQmrlM

### ted음성을 시연자 목소리로 바꾼 결과
https://drive.google.com/drive/folders/1NwWLql_pUyqAdhxIo5yG5lJpQT_1Xq0i 에서 WAV파일참조
### 목소리 합성 결과
원본1 => 시연목소리1 
원본2 => 시연목소리2
### 배경
쉐도잉은 영어스피킹을 학습하는 좋은 방법이다. 하지만 외국인발화자와 자신이 말한것을 비교하는 것이 영어초보자의 경우
쉽지가 않고 또한 따라한 후 피드백을 주관적인 판단에 의하여 진행하는 것이 단점이라고 생각하였다.그래서 발화자의 억양이나 강세는 그대로 유지하여 학습하되 음색만을 나의 목소리로 바꿔 들려주면 
도움이 되지 않을까?  라는 생각에 프로젝트를 진행해보았다.

### 사용 데이터
학습 컨텐츠로 TED를 사용하였다. TED에서 자막, 음성등을 크롤링하고 학습에 용이하도록 전처리를 하였다.

## 프로그램 기능

### 목소리 컨버트
TED 음성을 학습자의 목소리로 컨버트 하는 기능을 "내 목소리 듣기" 버튼을 눌러 사용할 수 있다.

### 쉐도잉 평가
페이지 오른쪽 하단에 쉐도잉결과를 강세,빠르기,Pitch, 그리고 구글의 STT를 활용하여 평가하는 기능을 넣었다.
또한 4가지 영역에 대하여 점수를 부여하고 최종점수까지 부여하여 사용자의 동기부여를 하였다.

## 모델 설명
VQ-VAE를 활용하여 음성합성을 진행하였다. 간략히 설명하자면 AE(Auto Encoder)는 단순히 입력값들에서 잠재요인들을 
뽑고 다시 이를 디코더를 통하여 원본과 가깝게 복원하는 기능밖에 가지지 못한다.
 VAE(Variational Auto Encoder)는 인풋데이터들을 통하여 인풋데이터들의 모집단의 분포를 추론한다. 모집단의 분포를 
일반적으로 정규분포로 가정하며, 이렇게 추정한 모집단의 분포를 바탕으로 디코더과정을 고치기 때문에 인풋값과는 유사하지만
새로운 데이터가 생성 될 수 있는 것이다.
VQ-VAE는 여기서 한발짝 나아가 latent factor값들을 discrete한 값으로 설정한다. 이러한 방법을 사용했을때 여러장점이 있지만
대표적으로 posterior collapse문제를 해결할수 있다고 알려져있다. 
테드음성데이터에서 억양,강세등을 잠재벡터로 저장하고, 디코더 과정에서 사용자의 음색을 적용하여 합성된 결과가 나오게 된다.

### 모델 설명 PPT
https://drive.google.com/drive/folders/1NwWLql_pUyqAdhxIo5yG5lJpQT_1Xq0i
